---
title: "Econometrics II: Assignment 2"
author: "Walter Verwer & Bas Machielsen"
date: \today
output:
  pdf_document: default
---

<style type="text/css">
code{
  font-size: 8px;
}

</style>


```{r setup, include=FALSE}
knitr::opts_chunk$set(include = FALSE)

if(Sys.info()["user"] == "bas"){ # Mijn Linux
    Sys.setenv(RETICULATE_PYTHON = "/home/bas/anaconda3/bin/python")
    library(reticulate)
    reticulate::use_python("/home/bas/anaconda3/bin/python")
    py_available(TRUE)
} else if(Sys.info()["user"] == "basmachielsen"){# Mijn Mac
    Sys.setenv(RETICULATE_PYTHON = "/opt/anaconda3/bin/python3")
    library(reticulate)
    reticulate::use_python("/opt/anaconda3/bin/python3")
    py_available(TRUE)
} else {
    Sys.setenv(RETICULATE_PYTHON = "C:\\Users\\walte\\anaconda3")
    library(reticulate)
    reticulate::use_python("C:\\Users\\walte\\anaconda3")
    py_available(TRUE)
}

# Hier kunnen we zien of alles is goed gegaan 
py_config()
```

## Question 1

First use pooled OLS to check the impact of including and excluding ASVABC on the estimate of $\alpha_1$. Present and explain the result.

```{python load packages, echo=FALSE}
import pandas as pd
import getpass


import statsmodels.api as sm
from statsmodels.iolib.summary2 import summary_col
from stargazer.stargazer import Stargazer

from IPython.core.display import HTML
import numpy as np
```


```{python read data, echo=FALSE}
path_walter = ("D:\\Files\\Git Projects\\ti_git_projects\\year_1\\block_3\\") \
                + ("econometrics2\\assignment2\\data\\NLSY2000RC_V2.csv")

if getpass.getuser()=='walte':
    earnings = pd.read_csv(path_walter)
    
else:
    earnings = pd.read_csv("~/Documents/git/econometrics2/assignment2/data/NLSY2000RC_V2.csv")

ivs = ['ASVABC','AGE', 'AGESQ','S','ETHBLACK','URBAN','REGNE','REGNC','REGW','REGS']
y = ['EARNINGS']

earnings = earnings.dropna()
```

```{python results='hide'}
model_with = sm.OLS(endog=earnings[y], exog=sm.add_constant(earnings[ivs])).fit()

model_without = sm.OLS(endog=earnings[y], exog=sm.add_constant(earnings[ivs[1:]])).fit()

stargazer = Stargazer([model_with,  model_without])
stargazer.covariate_order(ivs)

with open("table1.tex", "w") as f:
    f.write(stargazer.render_latex())
```

\input{table1.tex}

The inclusion of the proxy ability decreases the estimate for the coefficient of schooling. Hence, given all other standard assumptions, ability and schooling are positively correlated, and the omission of a proxy for ability overestimates the impact of schooling.

\clearpage

## Question 2

Perform a pooled OLS analysis to obtain insight in the heterogeneity of returns to schooling by ethnicity. Present the results and comment on the outcomes: what are the conclusions based on this?

```{python results='hide'}
# including a cross effect of schooling and ethnicity
earnings['BLACKxS'] = earnings['ETHBLACK'] * earnings['S']


ivs2 = ivs + ['BLACKxS']

est_ear_inter = sm.OLS(endog=earnings[y], exog = sm.add_constant(earnings[ivs2])).fit()

# estimating separate equations by ethnicity
earnings_noblack = earnings[earnings['ETHBLACK'] == 0]
earnings_black = earnings[earnings['ETHBLACK'] == 1]


est_ear_noblack = (sm.OLS(
    endog=earnings_noblack[y],
    exog=sm.add_constant(earnings_noblack[ivs]))
    .fit()
    )

est_ear_black = (sm.OLS(
    endog=earnings_black[y],
    exog=sm.add_constant(earnings_black[ivs]))
    .fit()
    )


stargazer = Stargazer([est_ear_inter, est_ear_noblack,  est_ear_black])
stargazer.covariate_order(['BLACKxS']+ivs)

stargazer.show_f_statistic = False
stargazer.show_residual_std_err = False
stargazer.custom_columns(['Interaction','Not Black', 'Black'], [1,1,1])

with open("table2.tex", "w") as f:
    f.write(stargazer.render_latex())

```

\input{table2.tex}

We can see that the interaction effect is insignificant: that is to say, there is no significant different between blacks and non-black in the influence of schooling on earnings. When we split up the sample into blacks and non-black, we get a slightly different view: the point estimate for the effect of schooling seems to be slightly lower for black people than for non-black people. However, as seen in the pooled regression with interaction effect, the differential impact is not statistically significant. 

\clearpage

## Question 3

Perform the analysis for heterogenous schooling effects using the random effects model. Present the results and compare the outcomes with the pooled OLS results obtained before. Interpret the outcomes.

<!-- Ik schat hier Random effects zonder intercept, zodat alle 4 de regio dummies erin kunnen. Ik heb dit ook in Python gedaan, en de resultaten zijn 100% identiek. Het probleem is alleen dat het super moeilijk is om van python linearmodels te exporteren naar .tex... echt een drama. Daarom heb ik maar plm en R gebruikt. -->

```{r, include = TRUE, echo = FALSE, results='asis'}
library(plm)
library(stargazer)

formula <- paste0(py$y, " ~ ", paste(py$ivs2, collapse = " + "), " + 0")

random_effects <- plm(formula = formula, 
                      data = py$earnings, 
                      index = c("ID","TIME"),
                      model = "random")

stargazer(random_effects, 
          header=FALSE)
```

```{python, eval = FALSE, include=FALSE}
# Hier is dus de Python code, run maar, en je kunt zien dat er hetzelfde uitkomt
from linearmodels import RandomEffects
import texression
from linearmodels import OLS

earnings_indexed = earnings.set_index(['ID', 'TIME'])
#earnings['TIME'] = time

hoi = earnings_indexed[ivs]
dep = earnings_indexed[y]

re_model = RandomEffects(dep, hoi).fit()

print(re_model.summary)
```

The point estimate for schooling is now close to the point estimate for schooling in the pooled OLS regression including the proxy for ability. Hence, the random effects estimator looks a lot like the pooled estimator, indicating that the contribution from the within group estimator is marginal. This can also be observed when looking at the decomposition of the explained variance: the between R-squared is larger than the within R-squared, indicating the model does a better job explaining the changes between individuals rather than individuals over time. 

(Still need to explain: black ethnicity $\cdot$ schooling is significant)

## Question 4

__A priori, would you plead for using fixed effects estimation or random effects estimation? Explain your answer.__

A priori, it would make more sense to use fixed-effects rather than random effects, because it is very likely that the unobservable individual components $\eta_i$ are correlated to the predictor variables $X$ rather than being random. For example, $\eta_i$ can be interpreted as being some measure of ability or innate willingness to exert effort, and that is likely related to age, schooling and test score. A possible correlation would violate the randomness of $\eta_i$ required by random effects, and hence, fixed effects would be preferred. 

\clearpage

## Question 5

__Apply the fixed effects estimator to analyze the heterogenous schooling effect. Interpret the outcomes.__

```{r fixedeffects, include = TRUE, echo = FALSE, results='asis'}
library(plm)
library(stargazer)

formula <- paste0(py$y, " ~ ", paste(py$ivs2, collapse = " + "))

fixed_effects <- plm(formula = formula, 
                      data = py$earnings, 
                      index = c("ID","TIME"),
                      model = "within")

stargazer(fixed_effects, 
          header=FALSE)
```

\clearpage
## Question 6

Fixed effects estimation may not be as efficient as random effects estimation, but is robust to correlation between regressors and the random effect. Can we perform a Hausman test in this context? Perform the test you propose.

The test tests the null hypothesis that the unique errors are not correlated with the regressors. 

```{r hausman, include=TRUE}
phtest(fixed_effects, random_effects)
```

The null hypothesis is rejected, implying that the unique parts are correlated with the regressors, and hence, random effects is an inconsistent estimator. 

## Question 7




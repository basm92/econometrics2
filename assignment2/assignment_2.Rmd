---
title: "Econometrics II: Assignment 2"
author: "Walter Verwer & Bas Machielsen"
date: \today
output:
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(include = FALSE)

if(Sys.info()["user"] == "bas"){ # Mijn Linux
    Sys.setenv(RETICULATE_PYTHON = "/home/bas/anaconda3/bin/python")
    library(reticulate)
    reticulate::use_python("/home/bas/anaconda3/bin/python")
    py_available(TRUE)
} else if(Sys.info()["user"] == "basmachielsen"){# Mijn Mac
    Sys.setenv(RETICULATE_PYTHON = "/opt/anaconda3/bin/python3")
    library(reticulate)
    reticulate::use_python("/opt/anaconda3/bin/python3")
    py_available(TRUE)
} else {
    Sys.setenv(RETICULATE_PYTHON = "C:\\Users\\walte\\anaconda3")
    library(reticulate)
    reticulate::use_python("C:\\Users\\walte\\anaconda3")
    py_available(TRUE)
}

# Hier kunnen we zien of alles is goed gegaan 
py_config()
```

## Question 1

First use pooled OLS to check the impact of including and excluding ASVABC on the estimate of $\alpha_1$. Present and explain the result.

```{python load packages, echo=FALSE}
import pandas as pd
import getpass

import statsmodels.api as sm
from statsmodels.iolib.summary2 import summary_col
from stargazer.stargazer import Stargazer

from IPython.core.display import HTML
import numpy as np
```


```{python read data, echo=FALSE}
path_walter = ("D:\\Files\\Git Projects\\ti_git_projects\\year_1\\block_3\\") \
                + ("econometrics2\\assignment2\\data\\NLSY2000RC_V2.csv")

if getpass.getuser()=='walte':
    earnings = pd.read_csv(path_walter)
    
else: # voor bas:
    earnings = pd.read_csv("~/Documents/git/econometrics2/assignment2/data/NLSY2000RC_V2.csv")

# Log earnings:
earnings['EARNINGS'] = np.log(earnings['EARNINGS'])

ivs = ['ASVABC','AGE', 'AGESQ','S','ETHBLACK','URBAN','REGNE','REGNC','REGW','REGS']
y = ['EARNINGS']

earnings = earnings.dropna()
```

```{python results='hide'}
model_with = sm.OLS(endog=earnings[y], exog=sm.add_constant(earnings[ivs])).fit()

model_without = sm.OLS(endog=earnings[y], exog=sm.add_constant(earnings[ivs[1:]])).fit()

stargazer = Stargazer([model_with,  model_without])
stargazer.covariate_order(ivs)

with open("table1.tex", "w") as f:
    f.write(stargazer.render_latex())
```

\input{table1.tex}

The inclusion of the proxy for ability decreases the estimate for the coefficient of schooling. Hence, given all other standard assumptions, ability and schooling are positively correlated, and the omission of a proxy for ability overestimates the impact of schooling. Something else that we are able to observe is that because of the inclusion of the test scores, the adjusted-$R^2$ increases by approximately 0.2 points. This implies that including test scores add about 2% to the model's ability to explain the observed variation. Finally, we could do a very rough t-test to compare both estimates of schooling. We observe a standard-error of about 0.001, and we observe a change in the coefficients of roughly 0.022. This implies that the t-value of the corresponding t-test is roughly 22. What this implies is that the observed difference in the estimate of the coefficient is significantly different.  
\clearpage

## Question 2

Perform a pooled OLS analysis to obtain insight in the heterogeneity of returns to schooling by ethnicity. Present the results and comment on the outcomes: what are the conclusions based on this?

```{r results='hide'}
library(lfe)
library(tidyverse)
library(stargazer)

earnings <- py$earnings %>%
  mutate(BLACKxS = ETHBLACK*S)

formula <- paste0(py$y, 
                  " ~ ",
                  "BLACKxS + ", 
                  paste(py$ivs, 
                        collapse = " +"), 
                  "+ 0")

# including a cross effect of schooling and ethnicity
crosseff <- lm(formula, 
               data = earnings)

summary(crosseff, 
        cluster="ID") 

# estimating separate equations by ethnicity
black_data <- earnings %>%
  as_tibble() %>%
  filter(ETHBLACK == 1)

formula <- "EARNINGS ~ ASVABC +AGE +AGESQ +S +URBAN +REGNE +REGNC +REGW +REGS + 0"

black <- lm(formula, data = black_data)

summary(black, 
        cluster="ID")

nonblack_data <- earnings %>%
  as_tibble() %>%
  filter(ETHBLACK == 0)

nonblack <- lm(formula, data = nonblack_data)

summary(nonblack, cluster="ID")
```

```{r, results='asis', include=TRUE, echo=FALSE}
stargazer(crosseff, black, nonblack,
          se=list(
            coef(summary(crosseff, cluster=c("ID")))[, 2], 
            coef(summary(black,cluster = c("ID")))[, 2],
            coef(summary(nonblack, cluster=c("ID")))[, 2]
                ),
          omit.stat=c("f", "ser"),
          header = FALSE
          ) 

```

```{python, include = FALSE, results='hide'}
# including a cross effect of schooling and ethnicity
earnings['BLACKxS'] = earnings['ETHBLACK'] * earnings['S']

ivs2 = ivs + ['BLACKxS']

est_ear_inter = sm.OLS(endog=earnings[y], exog = sm.add_constant(earnings[ivs2])).fit()

# estimating separate equations by ethnicity
earnings_noblack = earnings[earnings['ETHBLACK'] == 0]
earnings_black = earnings[earnings['ETHBLACK'] == 1]


est_ear_noblack = (sm.OLS(
    endog=earnings_noblack[y],
    exog=sm.add_constant(earnings_noblack[ivs]))
    .fit()
    )

est_ear_black = (sm.OLS(
    endog=earnings_black[y],
    exog=sm.add_constant(earnings_black[ivs]))
    .fit()
    )


stargazer = Stargazer([est_ear_inter, est_ear_noblack,  est_ear_black])
stargazer.covariate_order(['BLACKxS']+ivs)

stargazer.show_f_statistic = False
stargazer.show_residual_std_err = False
stargazer.custom_columns(['Interaction','Not Black', 'Black'], [1,1,1])

with open("table2.tex", "w") as f:
    f.write(stargazer.render_latex())

```

<!-- \input{table2.tex} -->

For the pooled models, we cluster the standard errors on the individual level, allowing for correlation in the error-term between observations belonging to the same individual. We can see that the interaction effect is significant: that is to say, there is a significant difference between blacks and non-black in the influence of schooling on earnings. When we split up the sample into blacks and non-black, we get a similar view: the point estimate for the effect of schooling seems to be slightly lower for black people than for non-black people. As seen in the pooled regression with interaction effect, the differential impact is statistically significant. This follows from the fact that the change is roughly 0.015 and if we take the highest standard error for the two (0.003), we would obtain a t-statistic of about 5. Which means that the observed difference is very likely to be because of ethnicity. Interestingly, the interaction approach results a very similar estimate and standard error as the difference between the two models. This implies that both methods give similar results. To conclude, we observe that there is a racial difference in the influence of schooling on earnings for blacks and non-blacks. It appears that blacks benefit more from schooling than whites, in terms of earnings.

\clearpage

## Question 3

Perform the analysis for heterogenous schooling effects using the random effects model. Present the results and compare the outcomes with the pooled OLS results obtained before. Interpret the outcomes.

<!-- Ik schat hier Random effects zonder intercept, zodat alle 4 de regio dummies erin kunnen. Ik heb dit ook in Python gedaan, en de resultaten zijn 100% identiek. Het probleem is alleen dat het super moeilijk is om van python linearmodels te exporteren naar .tex... echt een drama. Daarom heb ik maar plm en R gebruikt. 

W: Dit vind ik ook netter :)-->

```{r, include = TRUE, echo = FALSE, results='asis'}
library(plm)
library(stargazer)

formula <- paste0(py$y, " ~ ", paste(py$ivs2, collapse = " + "), " + 0")

random_effects <- plm(formula = formula, 
                      data = py$earnings, 
                      index = c("ID","TIME"),
                      model = "random")

stargazer(random_effects, 
          header=FALSE,
          title='Random effects model')
```

```{python, eval = FALSE, include=FALSE}
# Hier is dus de Python code, run maar, en je kunt zien dat er hetzelfde uitkomt
from linearmodels import RandomEffects
import texression
from linearmodels import OLS

earnings_indexed = earnings.set_index(['ID', 'TIME'])
#earnings['TIME'] = time

hoi = earnings_indexed[ivs]
dep = earnings_indexed[y]

re_model = RandomEffects(dep, hoi).fit()

print(re_model.summary)
```

The random effects model assumes that $\mathbb{E}[\eta_i | X_1, \dots, X_n] = 0$, in words, that the individual-specific effects are uncorrelated to the predictor variables. In this model, the point estimate for schooling is now close to the point estimate for schooling in the pooled OLS regression including the proxy for ability. Hence, the random effects estimator looks a lot like the pooled estimator, indicating that the contribution from the within group estimator is marginal. This can also be observed when looking at the decomposition of the explained variance: the between R-squared is larger than the within R-squared, indicating the model does a better job explaining the changes between individuals rather than individuals over time. There seems to be no differences in returns to education between individuals of different ethnicity: the interaction coefficient is insignificant. 

\clearpage

## Question 4

__A priori, would you plead for using fixed effects estimation or random effects estimation? Explain your answer.__

A priori, it would make more sense to use fixed-effects rather than random effects, because it is very likely that the unobservable individual components $\eta_i$ are correlated to the predictor variables $X$ rather than being random. For example, $\eta_i$ can be interpreted as being some measure of ability or innate willingness to exert effort, and that is likely related to age, schooling and test score. A possible correlation would violate the randomness of $\eta_i$ required by random effects, and hence, fixed effects would be preferred. 

## Question 5

__Apply the fixed effects estimator to analyze the heterogenous schooling effect. Interpret the outcomes.__

```{r fixedeffects, include = TRUE, echo = FALSE, results='asis'}
library(plm)
library(stargazer)

earnings <- py$earnings %>%
  mutate(BLACKxS = ETHBLACK * S)

formula <- paste0(py$y, " ~ ", paste(py$ivs2, collapse = " + "))

fixed_effects <- plm(formula = formula, 
                      data = earnings, 
                      index = c("ID","TIME"),
                      model = "within")

stargazer(fixed_effects, 
          header=FALSE)
```

Because of multicollinearity, one coefficient from the dummies is dropped. It appears to remain constant over time. 

\clearpage

## Question 6

__Fixed effects estimation may not be as effcient as random effcient estimation, but is robust to correlation between regressors and the random effcient. Can we perform a Hausman test in this context? Perform the test you propose. Fixed effects estimation may not be as efficient as random effects estimation, but is robust to correlation between regressors and the random effect. Can we perform a Hausman test in this context? Perform the test you propose.__

The test tests the null hypothesis that the unique errors are not correlated with the regressors. 

```{r hausman, include=TRUE}
phtest(fixed_effects, random_effects)
```

The null hypothesis is rejected, implying that the unique parts are correlated with the regressors, and hence, random effects is an inconsistent estimator. 

\clearpage 

## Question 7

__Perform Mundlak estimation of the model. Present the results of estimation and test for the joint sigificance of the within-group means.__

For this question we first need to estimate the time mean of the regressor variables, for every individual. Then we include those estimates in a random effects model and apply a Wald test on the coefficients of the time-meaned regressors.

Our results are shown below. In the Wald test output, one can see that the time-meaned regressors are highly jointly significant away from zero. This indicates that it is better to use the fixed effects model instead of the random effects model.

```{r mundlak, results='asis', warning=FALSE}
# 1. Estimate time means per individual and variable:
    # We moeten mergen, de mundlak part moet constant erbij toegevoegd worden, for elke t.
    # Dus voor elke individu neem de mean over de tijd en maak de dimensies gelijk aan Y_it

# 2. Use pggls() to estimate the feasible GLS of the model, use method = random:
    # Idem

# 3. Apply Wald test 

# wald.test(vcov(ppgls(model)), b=coeffs(ppgls(models)), Terms = 10:17, df = earnings)

library(aod)

# get average over time per worker
earnings <- py$earnings %>%
  mutate(BLACKxS = ETHBLACK * S)

X_hat <- earnings %>%
  group_by(ID) %>%
  summarise(across(everything(), mean)) %>%
  select(-TIME) # Drop TIME because unnecessary

colnames(X_hat)[c(-1)] <- paste(colnames(X_hat)[c(-1)], "MEAN", sep = "_")

# add to individual variables
earnings_with_mean <- left_join(earnings, X_hat, by = c("ID"))

mundlak <- pggls(EARNINGS ~  S + AGE + AGESQ + ETHBLACK + URBAN +
                   REGNE + REGNC + REGW  + ASVABC + BLACKxS +
                   S_MEAN + AGE_MEAN + AGESQ_MEAN + ETHBLACK_MEAN +
                   URBAN_MEAN + ASVABC_MEAN + REGNE_MEAN + REGNC_MEAN +
                   REGW_MEAN  + BLACKxS_MEAN,
                 data=earnings_with_mean,
                 model="random",
               index = c("ID")
                 )
```

```{r include = TRUE}
summary(mundlak)
```

```{r include = TRUE}
wald.test(vcov(mundlak), b=coef(mundlak), Terms = 12:19)
```


## Question 8
__What are your overall conclusions from the analysis of heterogeneity in returns to schooling by ethnicity?__


## Question 9
__To gain insight in the impact of nonresponse and attrition, the researcher applies a variant of the Verbeek and Nijman-test (see lecture slides). He defines the dummy variable $d_i$ which is 1 if the individual is in the panel for more than 5 waves, and is zero otherwise. Apply the Verbeek and Nijman test with this definition of $d_i$ (otherwise equal to the definition at the lecture slides). Draw conclusions and address practical problems you possibly met in implementing the test.__

We have simply applied a fixed effects panel data regression on both the full data set, as well as on the data set where we only take the individuals into account that are 5 or more times observed in the data set. We have done this by applying a filter by counting how many times a specific individual is in the data set, if the individual is counted 5 or more times, then it is included in the fixed effects regression. Our conclusion based on a Haussman test between the two estimated coefficient vectors for both data sets is that there is a significant difference. This tells us that there is attrition bias present in the data. However, we do have to note that this specification of the Verbeek and Nijman test does not compare a fully balanced model with our original unbalanced model. 

It actually compares two unbalanced models with each other. Even though this is the case we still obtain evidence of attrition bias due to an unobserved variable that is causing the attrition. The reason is, as stated before, that the two estimated coefficient vectors are different from each other. A practical problem that can arise (we did not have this problem) is that the sample size of the fully balanced model becomes simply too small to infere meaningful results. By taking out individuals that left before being in there for the 5$^{th}$, this prevents small sample size problems. A practical problem we did have was that we had to programme this filter ourselves, because it is a deviation from the standard Verbeek and Nijman methodology. But still this was a minor challenge to overcome, given the ease that this is programmed in R.

```{r verbeek_neijman, include=TRUE, echo=FALSE, results='asis'}
earnings <- py$earnings %>%
  mutate(BLACKxS = ETHBLACK * S)

frequencies <- earnings %>%
  count(ID)

earnings <- dplyr::left_join(earnings, frequencies, by = "ID")

# Unbalanced model:
unbalanced_formula <- paste0(py$y, " ~ ", paste(py$ivs2, collapse = " + "))

unbalanced_fixed_effects <- plm(formula = unbalanced_formula, 
                      data = earnings, 
                      index = c("ID","TIME"),
                      model = "within")

# Balanced model:
partial_unbalanced_formula <- paste0(py$y, " ~ ", paste(py$ivs2, collapse = " + "))

partial_unbalanced_fixed_effects <- plm(formula = partial_unbalanced_formula, 
                      data = earnings %>%
                        filter(n >= 5), 
                      index = c("ID","TIME"),
                      model = "within")


stargazer(unbalanced_fixed_effects, 
          partial_unbalanced_fixed_effects, 
          column.labels = c("Unbalanced",
                            "Balanced"),
          hedaer=FALSE
          )
```

```{r include=TRUE}
phtest(unbalanced_fixed_effects, partial_unbalanced_fixed_effects)
```










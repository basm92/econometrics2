---
title: "Assignment 3"
author: "Walter Verwer & Bas Machielsen"
date: \today
output:
  pdf_document:
    includes:
      in_header: "preamble.tex"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Register an inline hook (set rounding to 3 digitis):
# knitr::knit_hooks$set(inline = function(x) {
#   x <- sprintf("%1.3f", x)
#   paste(x, collapse = ", ")
# })

library(stargazer)
library(tidyverse)
library(haven)
library(knitr)
library(lmtest)
library(sandwich)

# Import Stata dataset
bonus <- haven::read_dta("./data/bonus.dta")

```

## Question 1

### 1.1

```{r warning=FALSE, message=FALSE}
data <- tribble(
    ~ color, ~ no_treated, ~ no_contr, ~ avg_treated, ~avg_control,
    "purple", 100, 100, 9, 7,
    "blue", 75, 25, 13, 8,
    "green", 25, 75, 10, 9
)

data %>%
    group_by(color) %>%
    summarize(treatment_effect = avg_treated - avg_control) %>%
    kable(caption = "Treatment effect per color")

```

### 1.2

The ATE is defined as $\mathbb{E}[\delta] = \mathbb{E}[Y^*_1] - \mathbb{E}[Y^*_0]$ which are the expectations of the potential outcomes. In general, these two variables are not observed. Under the _random assignment_ assumption, we assume that $\mathbb{E}[Y_1^*] = \mathbb{E}[Y_1^* | D = 1]$ and $\mathbb{E}[Y_0^*] = \mathbb{E}[Y_0^* | D = 0]$, which can be estimated by their sample by their sample equivalents:

```{r warning=FALSE, message=FALSE}
data %>%
    summarize(
        e_y1_d_is_1 = (9*100 + 13 * 75 + 10 * 25) / sum(no_treated),
        e_y0_d_is_0 = (7 * 100 + 8 * 25 + 9 * 75) / sum(no_contr)) %>%
    summarize(ate = e_y1_d_is_1 - e_y0_d_is_0) %>%
    kable(caption = "ATE")

```

### 1.3

The ATET is defined as $\mathbb{E}[\delta | D = 1] = \mathbb{E}[Y^1 | D =1] - \mathbb{E}[Y^0 | D=1]$. The first term is readily observable. The second term is estimated by us as $\hat{\mathbb{E}}[Y^0 | D =1] = \mathbb{E}[Y^0 | D = 0]$. Hence:

```{r warning=FALSE, message=FALSE}
data_ate <- data %>%
    mutate(n = no_treated + no_contr) %>%
    summarize(e_y1_d_is_1 = (9 * 100 + 13 * 75 + 10 * 25) / sum(no_treated),
              e_y0_d_is_0 = (7 * 100 + 8 * 25 + 9 * 75) / sum(no_contr))

data_ate 

data_ate %>%
    summarize(atet = e_y1_d_is_1 - e_y0_d_is_0) %>%
    kable(caption = "ATET")
```

So the $ATE = ATET$ (because of randomization). 

# Question 2

### 2.1

__Compute the fraction of students in all three groups (control, low-reward and high-reward) that complete all first-year courses before the start of the second academic year. Show within a table that background characteristics are balanced over the treatment groups.__


```{r message=FALSE}
bonus_clean <- bonus %>%
    pivot_longer(cols = c(bonus0, bonus500, bonus1500), 
                 names_to = "kind_treatment",
                 values_to = "treatment") %>%
    filter(treatment == 1) 

bonus_clean %>%
    group_by(kind_treatment) %>%
    summarize(fraction_pass = sum(pass)/n()) %>%
    kable(caption = "Fraction passed per treatment", digits = 3)

```

```{r message = FALSE}

#Drop the outcome variables
bonus_clean %>%
    group_by(kind_treatment) %>%
    select(-c(pass, stp2001, stp2004, dropout)) %>%
    summarize(across(p0:math, 
                     list(mean = ~ mean(., na.rm = TRUE), 
                          sd = ~ sd(., na.rm = TRUE)))) %>%
    pivot_longer(-kind_treatment, names_to = "variable") %>%
    separate(variable, into = c("var", "statistic"), sep = "_") %>%
    pivot_wider(names_from = c(kind_treatment, statistic)) %>%
    kable(caption = "Means and SDs according to treatment", digits = 3)

```


### 2.2

__Use the linear probability model to regress the dummy variable for completing all courses on the assignment of the three treatment groups. Interpret the treatment effects. Next include as additional regressors father's education, high-school math score and the subjective assessment about the pass probability.__

For table \ref{tab:123}, in the first model, we find that students who receive the 500 bonus are 0.007 percentage points more likely to pass the first year, and students who receive the f 1,500 bonus are 0.046 percentage points more likely to pass the first year, both relative to the group that receives no bonus. This effect is, however, not statistically significant, indicating that there is a high variance in passing within treatment groups, or, alternatively, that the sample size is too sample to statistically detect a relatively small effect size.

The point estimates change only slightly when including a vector of control variables, indicating that the treatment conditional on these (potential) confounders does not significantly increase the probability of passing. What we however find when we include the additional variables, is that the adjusted-$R^2$ increases a lot, meaning a very high increase in explanatory power. These variables added also appear to be highly statistically significant.

### 2.3

__Next also include as regressors in your model whether a student has a job and the amount of study effort. Comment on this approach. Do you consider this an improvement over (ii)?__

The results are again displayed in table \ref{tab:123}. Including job and study effort increases the adjusted-$R^2$. The coefficient of $P_0$ becomes less insignificant, and effort is highly signicicant. This indicates that there is probably some correlation between $P_0$ and effort that was previously not captured by the model. Thus indicating an omitted variable bias problem beforehand. The rest of the coefficients and standard errors do not change that much by the additional variables. However, seeing that there is some indication of omitted variable bias, we conclude that this approach is an improvement.

```{r pass on groups, results='asis'}
attach(bonus)

# We need to regress pass on the treatment group assignment. This is
# a simple linear probability model. Model is denoted by prob_1. 
# Note, we need to omit bonus0, cause of a dummy variable trap.
prob_1 <- lm(pass ~ bonus500 + bonus1500, data=bonus)
# Same as before, but now with some extra variables
prob_2 <- lm(pass ~ bonus500 + bonus1500 + fyeduc + math + p0, data=bonus)
# for q2.3:
prob_3 <- lm(pass ~ bonus500 + bonus1500 + fyeduc + math + p0 + job + effort, data=bonus)

# # q2.4; I think we should take the largest model. BAS???:
# prob_4 <- lm(pass ~ bonus500 + bonus1500 + fyeduc + math + p0 + job +
# effort + dropout + stp2001 + stp2004, data=bonus)

# Implement HC-robust standard errors (standard in linear prob model)
library(sandwich)
cov1 <- vcovHC(prob_1, type = "HC")
robust_se1 <- sqrt(diag(cov1))

cov2 <- vcovHC(prob_2, type = "HC")
robust_se2 <- sqrt(diag(cov2))

cov3 <- vcovHC(prob_3, type = "HC")
robust_se3 <- sqrt(diag(cov3))

# Create table:
stargazer(prob_1, prob_2, prob_3, header=FALSE, style='aer', label='tab:123',
           se = list(robust_se1, robust_se2, robust_se3))
```




### 2.4

__Use your preferred model specifcation to estimate the effects of the financial incentives on some other outcomes: dropping out and credit points collected (in the first year and after three years).__

```{r echo=FALSE, results='asis'}
prob_4 <- lm(dropout~ bonus500 + bonus1500 + fyeduc + math + p0 + job + effort,
             data = bonus)
prob_5 <- lm(stp2001 ~  bonus500 + bonus1500 + fyeduc + math + p0 + job + effort,
             data = bonus)
prob_6 <- lm(stp2004 ~  bonus500 + bonus1500 + fyeduc + math + p0 + job + effort,
             data=bonus)

cov4 <- vcovHC(prob_4, type = "HC")
robust_se4 <- sqrt(diag(cov4))

cov5 <- vcovHC(prob_5, type = "HC")
robust_se5 <- sqrt(diag(cov5))

cov6 <- vcovHC(prob_6, type = "HC")
robust_se6 <- sqrt(diag(cov6))

stargazer(prob_4, prob_5, prob_6, header=FALSE, style='aer', label='tab:456', 
          se = list(robust_se4, robust_se5, robust_se6))

```

We have presented our results in table \ref{tab:456}. We observe similar effects as before. It appears that math and effort remain highly significant 

### 2.5

__Given the sample size and the estimates you have obtained above, what would be the minimum detectable effect size of this experiment?__
In the next model, we observe that the point estimates for the treatment effects increase a bit, indicating that effort was a confounder. Hence, we do consider this to be an improvement, although the treatment effects are still not significantly different from zero. 

<!-- @Bas: wat denk jij? De MDE zou toch een fucntie moeten zijn van onder andere power? Dus we zouden voor meerder waardes van power de MDE moeten uitrekenen toch? -->

```{r power and MDE, results='asis'}
library(estimatr)
power <- lm_robust(pass ~ bonus500 + bonus1500 + fyeduc + math + p0 + job + effort, data=bonus)

# For now the constants:
n <- nrow(bonus)
df <- n - length(prob_3$coefficients)
alpha <- 0.05
t_95 <- qt(1-alpha/2, df)
sigma2 <- var(prob_3$residuals)
p<-(83+84)/(82+83+84)

# How much power do we want? Range of powers:
q <- seq(from=0.6, to=0.9, by=0.1)

# Init empty vector of t values for the power:
t_q = rep(0, length(q))

# Fill vector iteratively and compute MDE for bonus500:
mde <- cbind(q*100, rep(0, length(q)))
counter <- 1
for (i in q){
    t_q[counter] <- qt(1-i, df)  # A check: from slides, t_0.7 = -0.525...

    mde[counter,2] <- (t_95 - t_q[counter]) * sqrt( (1/(p*(1-p))) * (sigma2 / n) )
    
    counter <- counter + 1
}

kable(mde, col.names = c('Power (%)','MDE'))

```


### 2.6

__Initially, the researchers were aiming at an increases in the pass rate of 10% points. How large should the sample size of the experiment have been in that case?__

The proportion of treated subjects $p = \frac{83+84}{82+83+84} = 0.67$. Then in order to obtain the minimum size of the sample, we have re-written the general equation for the minimum detectable effect size in terms of $n$, the sample size. Formally, it takes the following form.

\begin{equation}
n = \frac{\sigma^2}{p(1-p)} / \left(\frac{mde}{(t_{1-\alpha}-t_{1-q})}\right)^2
\end{equation}

We have to however assume that we have a sufficiently large sample size that we can use the quantiles of the normal distribution. The reason is that the quantiles of the t-distribution depend on the number of degrees of freedom, which in turn depends on the sample size. Thus, we can not find an explicit expression in terms of $n$.

```{r}
bonus_clean %>%
    group_by(kind_treatment) %>%
    summarize(test = n()) %>% 
    kable()

# Constants:
power_req <- 0.7
mde_req <- 0.1
n_95 <- qnorm(1-alpha/2) 
n_q <- qnorm(1-power_req)

# Formula:
n_min <- (sigma2/(p*(1-p))) / (mde_req/(n_95-n_q))^2



```

Filling in the formula, we obtain that the sample size should be approximately `r round(n_min,0)`.







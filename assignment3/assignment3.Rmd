---
title: "Assignment 3"
author: "Walter Verwer & Bas Machielsen"
date: \today
output:
  pdf_document:
    includes:
      in_header: "preamble.tex"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Register an inline hook (set rounding to 3 digitis):
knitr::knit_hooks$set(inline = function(x) {
  x <- sprintf("%1.3f", x)
  paste(x, collapse = ", ")
})

library(stargazer)
library(tidyverse)
library(haven)
library(knitr)
library(lmtest)
library(sandwich)

# Import Stata dataset
bonus <- haven::read_dta("./data/bonus.dta")

```

## Question 1

### 1.1

```{r warning=FALSE, message=FALSE}
data <- tribble(
    ~ color, ~ no_treated, ~ no_contr, ~ avg_treated, ~avg_control,
    "purple", 100, 100, 9, 7,
    "blue", 75, 25, 13, 8,
    "green", 25, 75, 10, 9
)

data %>%
    group_by(color) %>%
    summarize(treatment_effect = avg_treated - avg_control) %>%
    kable(caption = "Treatment effect per color")

```

### 1.2

The ATE is defined as $\mathbb{E}[\delta] = \mathbb{E}[Y^*_1] - \mathbb{E}[Y^*_0]$ which are the expectations of the potential outcomes. In general, these two variables are not observed. Under the _random assignment_ assumption, we assume that $\mathbb{E}[Y_1^*] = \mathbb{E}[Y_1^* | D = 1]$ and $\mathbb{E}[Y_0^*] = \mathbb{E}[Y_0^* | D = 0]$, which can be estimated by their sample by their sample equivalents:

```{r warning=FALSE, message=FALSE}
data %>%
    summarize(
        e_y1_d_is_1 = (9*100 + 13 * 75 + 10 * 25) / sum(no_treated),
        e_y0_d_is_0 = (7 * 100 + 8 * 25 + 9 * 75) / sum(no_contr)) %>%
    summarize(ate = e_y1_d_is_1 - e_y0_d_is_0) %>%
    kable(caption = "ATE")

```

### 1.3

The ATT is defined as $\mathbb{E}[\delta | D = 1] = \mathbb{E}[Y^1 | D =1] - \mathbb{E}[Y^0 | D=1]$. The first term is readily observable. The second term is estimated by us as $\hat{\mathbb{E}}[Y^0 | D =1] = \mathbb{E}[Y^0 | D = 0]$. Hence:

```{r warning=FALSE, message=FALSE}
data_ate <- data %>%
    mutate(n = no_treated + no_contr) %>%
    summarize(e_y1_d_is_1 = (9 * 100 + 13 * 75 + 10 * 25) / sum(no_treated),
              e_y0_d_is_0 = (7 * 100 + 8 * 25 + 9 * 75) / sum(no_contr))

data_ate 

data_ate %>%
    summarize(att = e_y1_d_is_1 - e_y0_d_is_0) %>%
    kable(caption = "ATT")
```

So the $ATE = ATT$ (because of randomization). 

# Question 2

### 2.1

__Compute the fraction of students in all three groups (control, low-reward and high-reward) that complete all first-year courses before the start of the second academic year. Show within a table that background characteristics are balanced over the treatment groups.__


```{r message=FALSE}
bonus_clean <- bonus %>%
    pivot_longer(cols = c(bonus0, bonus500, bonus1500), 
                 names_to = "kind_treatment",
                 values_to = "treatment") %>%
    filter(treatment == 1) 

bonus_clean %>%
    group_by(kind_treatment) %>%
    summarize(fraction_pass = sum(pass)/n()) %>%
    kable(caption = "Fraction passed per treatment", digits = 3)

```

```{r message = FALSE}

#Drop the outcome variables
bonus_clean %>%
    group_by(kind_treatment) %>%
    select(-c(pass, stp2001, stp2004, dropout)) %>%
    summarize(across(p0:math, 
                     list(mean = ~ mean(., na.rm = TRUE), 
                          sd = ~ sd(., na.rm = TRUE)))) %>%
    pivot_longer(-kind_treatment, names_to = "variable") %>%
    separate(variable, into = c("var", "statistic"), sep = "_") %>%
    pivot_wider(names_from = c(kind_treatment, statistic)) %>%
    kable(caption = "Means and SDs according to treatment", digits = 3)

```


### 2.2

__Use the linear probability model to regress the dummy variable for completing all courses on the assignment of the three treatment groups. Interpret the treatment effects. Next include as additional regressors father's education, high-school math score and the subjective assessment about the pass probability.__


### 2.3

__Next also include as regressors in your model whether a student has a job and the amount of study effort. Comment on this approach. Do you consider this an improvement over (ii)?__


```{r pass on groups, results='asis'}
attach(bonus)

# We need to regress pass on the treatment group assignment. This is
# a simple linear probability model. Model is denoted by prob_1. 
# Note, we need to omit bonus0, cause of a dummy variable trap.
prob_1 <- lm(pass ~ bonus500 + bonus1500, data=bonus)
# Same as before, but now with some extra variables
prob_2 <- lm(pass ~ bonus500 + bonus1500 + fyeduc + math + p0, data=bonus)
# for q2.3:
prob_3 <- lm(pass ~ bonus500 + bonus1500 + fyeduc + math + p0 + job + effort, data=bonus)

# # q2.4; I think we should take the largest model. BAS???:
# prob_4 <- lm(pass ~ bonus500 + bonus1500 + fyeduc + math + p0 + job + effort + dropout + stp2001 + stp2004, data=bonus)

# Implement HC-robust standard errors (standard in linear prob model)
#library(sandwich)
#cov <- vcovHC(reg.model, type = "HC")
#robust.se <- sqrt(diag(cov))

# Create table:
stargazer(prob_1, prob_2, prob_3, header=FALSE, style='aer')
```


In the first model, we find that students who receive the 500 bonus are 0.007 percentage points more likely to pass the first year, and students who receive the f 1,500 bonus are 0.046 percentage points more likely to pass the first year, both relative to the group that receives no bonus. This effect is, however, not statistically significant, indicating that there is a high variance in passing within treatment groups, or, alternatively, that the sample size is too sample to statistically detect a relatively small effect size.

The point estimates change only slightly when including a vector of control variables, indicating that the treatment conditional on these (potential) confounders does not significantly increase the probability of passing. 


### 2.4

__Use your preferred model specifcation to estimate the effects of the financial incentives on some other outcomes: dropping out and credit points collected (in the first year and after three years).__

```{r echo=FALSE, results='asis'}
# I think we should take the largest model. BAS???:
# Du hast Recht und wir sind Eindverstanden!
prob_4 <- lm(dropout~ bonus500 + bonus1500 + fyeduc + math + p0 + job + effort,
             data = bonus)
prob_5 <- lm(stp2001 ~  bonus500 + bonus1500 + fyeduc + math + p0 + job + effort,
             data = bonus)
prob_6 <- lm(stp2004 ~  bonus500 + bonus1500 + fyeduc + math + p0 + job + effort,
             data=bonus)

stargazer(prob_4, prob_5, prob_6, style='aer')
```

### 2.5

__Given the sample size and the estimates you have obtained above, what would be the minimum detectable effect size of this experiment?__
In the next model, we observe that the point estimates for the treatment effects increase a bit, indicating that effort was a confounder. Hence, we do consider this to be an improvement, although the treatment effects are still not significantly different from zero. 

<!-- @Bas: wat denk jij? De MDE zou toch een fucntie moeten zijn van onder andere power? Dus we zouden voor meerder waardes van power de MDE moeten uitrekenen toch? -->

```{r power and MDE, results='asis'}

# For now the constants:
n <- length(p0)
df <- n - length(prob_3$coefficients)
alpha <- 0.05
t_95 <- qt(1-alpha/2, df)
sigma2 <- var(prob_4$residuals)

# Ik heb deze maar pre specified. We hebben twee verschillende treatments,
# zouden we dan niet twee power calculaties moeten doen?
p<-0.5

# How much power do we want? Range of powers:
q <- seq(from=0.6, to=0.9, by=0.1)

# Init empty vector of t values for the power:
t_q = rep(0, length(q))

# Fill vector iteratively and compute MDE for bonus500:
mde <- cbind(rep(0, length(q)),rep(0, length(q)))
counter <- 1
for (i in q){
    t_q[counter] <- qt(1-i, df)  # A check: from slides, t_0.7 = -0.525...

    mde[counter,1] <- (t_95 - t_q[counter]) * sqrt( (1/(p*(1-p))) * (sigma2 / n) )
    
    counter <- counter + 1
}

# Treatment bonus1500:
counter <- 1
for (i in q){
    t_q[counter] <- qt(1-i, df)  # A check: from slides, t_0.7 = -0.525...

    mde[counter,2] <- (t_95 - t_q[counter]) * sqrt( (1/(p*(1-p))) * (sigma2 / n) )

    counter <- counter + 1
}

kable(mde)

```


### 2.6

__Initially, the researchers were aiming at an increases in the pass rate of 10% points. How large should the sample size of the experiment have been in that case?__

The proportion of treated subjects $p = \frac{83+84}{82+83+84} = 0.67$. 

```{r}
bonus_clean %>%
    group_by(kind_treatment) %>%
    summarize(test = n()) %>% 
    kable()

```

The estimated variance of the error term in the full model is

We know that the minimum effect size as a function of $p$, power $q$, level $\alpha$, 




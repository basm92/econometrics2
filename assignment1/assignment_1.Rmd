---
title: "Assignment 1"
author: "Walter Verwer    &     Bas Machielsen"
institute: test
date: \today
email: 
output:
  pdf_document: 
    keep_tex: yes
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, size = 'small')

options(digits=3) # Set rounding to 3 digitis

if (!require("pacman")) install.packages("pacman")

pacman::p_load(tidyverse,
               stargazer,
               readr,
               ivreg,
               sampleSelection,
               estimatr,
               texreg)
```

## Question 1: The sample selection model. 

A researcher aims to gain insight in the potential earnings of the non-employed. (In the data, the non-employed can be identified by a missing value for the earnings variable). She realizes that the sample of observed wages may be subject to sample selection.

__(a) Run an OLS regression for log-earnings on schooling, age, and age squared. Present the results and comment on the estimates.__
    
```{r, include=FALSE}
data <- read_csv("./Data/logEarnings.csv")
```
    
```{r results='asis'}
model_1 <- lm(data = data, formula = logWage ~ schooling + age + age2)

results_1 <- summary.lm(model_1)
coeffs_1 <- results_1$coefficients[,1]
pvals_1 <- results_1$coefficients[,4]

stargazer(model_1, style = "AER",
          font.size = "small",
          header = F, label = 'tab:q1_a_ols',
          title = 'OLS regression for log-earnings on schooling, age and age squared.')
```

The results show that one additional year of schooling has an effect of `r coeffs_1[2]` on log(Wage), which means that one additional year of schooling has an estimated `r coeffs_1[2]*100`% effect on wages earned. This result is highly significant (p-value is `r pvals_1[2]`) Another result, shown in figure \ref{tab:q1_a_ols} is that being one year older has an estimated effect of `r coeffs_1[3]` on log(Wage). Thus, being one year older is estimated to have a `r coeffs_1[3]*100`% on wages. This result is not significant at a common level (p-value is `r pvals_1[3]`). The third estimated coefficients is the one corresponding to the variable age squared. It has an estimated coefficient of `r coeffs_1[4]`, which represents the estimated effect of a one unit increase in age squared on log(Wage). This also means that a one unit increase in age squared is equal to an estimate effect of `r coeffs_1[4]*100`% on the linear representation of wage. This effect is not significant at common levels, because the p-value is `r pvals_1[4]`. Finally, the estimated constant in the model is estimated at `r coeffs_1[1]`. This means that if all other variables are zero, then the log(Wage) will be equal to `r coeffs_1[1]`. Thus, if all other variables are zero, then wage is estimated to be equal to exp(`r coeffs_1[1]`)=`r exp(coeffs_1[1])`. This is an extremely high number given the characteristics of the wage variable. However, this result is highly significant, because the p-value is `r pvals_1[1]`.

__(b) Briefly discuss the sample selection problem that may arise in using these OLS estimates for the purpose of predicting the potential earnings of the non-employed. Formulate the sample selection model. In your answer, include an explanation why OLS may fail in this context.__

An individual is only in this data set if they earn wages, i.e. if they are employed. Being employed itself is not randomly allocated, but rather, a function of e.g. age, age^2, and schooling. Also, employment status follows from labor supply and demand forces. Hence, the estimates of schooling on earnings are conditional on having earnings to begin with, whereas unbiased estimates must also include those individuals. 
Formally, $\mathbb{E}[\text{Earnings}] = \mathbb{E[\text{Earnings}|\text{Having a job}]} \cdot \mathbb{P}[\text{Having a job}] + \mathbb{E[\text{Earnings}|\text{Not having a job}]} \cdot (1-\mathbb{P[\text{Having a job}]})$. The given estimation only concerns $\mathbb{E[\text{Earnings}|\text{Having a job}]}$.

The sample selection model is given by the following two equations. In equation \ref{eq:select}, $I_i$ denotes an indicator variable which is equal to 1 if we observe the wage of an individual, and $Z_i$ denotes a vector of explanatory variables for the probability of an individual being employed or not.

<!-- Still need to add specific variables! As X variables we could do the variables from q1a, and then for the selection equation do the marriage status variable? Should we include the exclusion restriction variable in the second equation? I.e. is Z a subset of X? -->

<!-- Bas: Z is never a subset of X! There should be at least 1 variable in Z that is not in X -->  

\begin{equation}
\mathbb{P}[I_i=1|Z]=\mathbf{\Phi} (Z_i'\gamma)
\label{eq:select}
\end{equation}

Under our distributional assumptions, in the selection model $v_i \sim N(0,1)$, and therefore $P(I_i=1) = P(I_i^* > 0) = \bf{\Phi}(Z_i^{'} \gamma)$, where $\Phi$ denotes a normal CDF. Note that the model used in this situation concerns a probit model, which has the goal to estimate the probability that an individual is employed.

The second equation is concerned with explaining the wage of an individual. It is given by the following equation.

\begin{equation}
Y_i^* = X_i'\beta + U_i
\label{eq:effect}
\end{equation}

In equation \ref{eq:effect}, $Y_i^*$ denotes the observed log(Wage), $X_i$ are the explanatory regressors for explaining log(Wage).

__(c) Which variable in your data may be a suitable candidate as an exclusion restriction for the sample selection model?__

For an exclusion restriction variable, we need a variable that is theoretically unrelated to earnings, but related to the probability of having a job. Empirically, we need a variable significantly different from zero in the selection equation and does not have an effect in the equation intended to explain the potential earnings of the non-employed. 

A potential candidate is this a variable that matters for being employed or not, but does not influence the height of the wage. We believe that marriage status could be a suitable candidate variable. The reason being that marriage status could matter for being employed or not, because if one is not married, the person is more likely to be the only person that has to provide the necessary funds of living. If someone is married however, than it is more likely that this person is not employed, because it might be the case that the partner provides. Marriage status is arguably a variable that does not provide a direct effect on the height of wages earned. Seeing as both criteria are met, we conclude that marriage status is a suitable candidate for an exclusion restriction.

__(d) Estimate the sample selection model with the Heckman two-step estimator, both with and without the exclusion restriction and compare the outcomes.__

For this question we are asked to estimate the Heckman two-step estimator, both with and without the exclusion variable. We have argued that married would be a suitable candidate for this variable. In the code below we have done the following. First we have estimated the sample selection model with the two-step approach, _including_ the exclusion variable in the selection regression, and _excluding_ it in the estimating regression. This is in a way as it should be done. The second thing we did was estimating the selection regression _without_ the exclusion variable married and in the second stage using the exact same collection of independent variables in the estimation regression. One thing to note about our code is that we have used our own code to produce the two-step estimator as well as a package. Our own code produced the exact same results as the package. Seeing as the package provides us with more detailed results, we show it's results in our output table, displayed in table \ref{tab:q1_d}.

```{r estimate_two-step, results='asis'}
# Construct I (I=1 for y_i^* != na, else 0)
data$I <- ifelse(is.na(data$logWage) , 0, 1) # if na, then I is zero. Else 1.

## Two stage approach without package:
# Stage 1:
# probit <- glm(I ~ schooling + age + age2 + married,
#               family = binomial(link = "probit"),
#               data = data)
# 
# # Construct variable for stage 2:
# Z_gamma <- cbind(1,data$schooling, data$age, data$age2, data$married) %*% coef(probit)
# inverse_mills_ratio <- dnorm(Z_gamma, mean=0, sd=1) / pnorm(Z_gamma, mean=0, sd=1)
# 
# # Stage 2:
# sample_selection_2s <- lm_robust(logWage ~ schooling + age + age2 + inverse_mills_ratio,
#                             se_type='HC1' ,data=data)

sample_selection_2s_with <- selection(I ~ schooling + age + age2 + married, 
                                logWage ~ schooling + age + age2, data=data, 
                                method='2step')
coeffs_sample_selection_2s_with <- sample_selection_2s_with$coefficients


## using package 'sampleSelection' to get maximum likelihood estimates:
sample_selection_2s_without <- selection(I ~ schooling + age + age2, 
                                logWage ~ schooling + age + age2, data=data, 
                                method='2step')
coeffs_sample_selection_2s_without <- sample_selection_2s_without$coefficients


# Obtain output:
stargazer(sample_selection_2s_with, sample_selection_2s_without,
          style = "AER",
          font.size = "small",
          header = F, label = 'tab:q1_d',
          column.labels = c("Two-step with married", "Two-step without married"),
          title = 'Log earnings sample selection regression with two-step approach, 
          with and without the exclusion variable.')
```

For our results we first note an important difference between the two choices of independent variable selections. The inverse Mills ratio of the model that does not include marriage in the selection stage is perfectly co linear with the rest of the explanatory variables. The result of this is that our standard errors are much larger for the model that is estimated without marriage than for the model that is estimated with marriage. From this we can conclude that excluding marriage leads to a large loss of estimation efficiency. Another observation that can be made is the change in the point estimates of the coefficients. For example, the constant changes from `r coeffs_sample_selection_2s_with[6]` with marriage, to `r coeffs_sample_selection_2s_without[5]` without marriage. Something else that can be observed is that $\rho>1$ for the model without marriage included in the selection equation. This is not possible given the fact that $\rho$ represents a correlation coefficient and thus should be between 0 and 1 in absolute value. A final observation that can be made is the large difference in the inverse Mill's ratio coefficients and standard error. That is the coefficient for the model with marriage is smaller and negative, in comparison to the model without marriage. For the standard errors, the model with marriage appears to be more efficient than the model without marriage.

__(e) Estimate the sample selection model with Maximum Likelihood, both with and without the exclusion restriction and compare the outcomes.__

```{r estimate_ml, results='asis'}
# Construct I (I=1 for y_i^* != na, else 0)
sample_selection_ml_with <- selection(I ~ schooling + age + age2 + married, 
                                logWage ~ schooling + age + age2, data=data, 
                                method='ml')
coeffs_sample_selection_ml_with <- sample_selection_ml_with$estimate[6:9]


## using package 'sampleSelection' to get maximum likelihood estimates:
sample_selection_ml_without <- selection(I ~ schooling + age + age2, 
                                logWage ~ schooling + age + age2, data=data, 
                                method='ml')
coeffs_sample_selection_ml_without <- sample_selection_ml_without$coefficients

# Obtain output:
stargazer(sample_selection_ml_with, sample_selection_ml_without,
          style = "AER",
          font.size = "small",
          header = F, label = 'tab:q1_e', digits=3,
          column.labels = c("ML with married", "ML without married"),
          title = 'Log earnings sample selection regression with maximum likelihood, 
          with and without the exclusion variable.')
```

In tabel \ref{tab:q1_e} we have displayed our estimation results using maximum likelihood, for the model with and without the exclusion restrictions. Again we observe a change in the point estimates as a result of the change in variable selection. An interesting observation to be made is that we are unable to retrieve standard errors for the model where we have excluded marriage. For the estimate of the correlation coefficient $\rho$ we notice a similar result for the models where we used the two-stage approach. We observe that the correlation coefficient moves from being negative under the model with marriage to 1.000 under the model without marriage.


__(f) On the basis of your results, how would you specify the distribution of potential earnings for the non-employed?__

For this question we can characterise the distribution of potential earning for the non-employed by using our model based on maximum likelihood and with marriage. The reason for the choice of maximum likelihood is that maximum likelihood is more efficient than the two-step approach, because we have hetereoskedastic errors for the two-step approach. The way we characterise the distribution is by predicting the values of the log(Wage) of the unemployed individuals. This is done by simply filling in the observed data for the unemployed in the model and then predict via the estimated model parameters. The code that makes the prediction is shown below, as well as a kernel density plot of the predicted log(Wage) of the unemployed.

```{r fig_density_log_wage, result='asis', fig.cap="\\label{fig:figs}Kernel density plot of predicted $log(Wage)$ of the unemployed.", fig.align="center"}
# Predict log(Wage):
data$est_log_wage<-NaN
for (i in c(1:nrow(data))){
  data$est_log_wage[i] <- coeffs_sample_selection_ml_with %*% cbind(1, 
                                                                    data$schooling,
                                                                    data$age, 
                                                                    data$age2)[i,1:4]
}

# Dummy that is 1 for being unemployed:
data$d_unem <- ifelse(is.na(data$logWage) , 1, NaN) # if na, then d_unem is 1. Else NaN.

# Construct vector of unemployed log(Wage) predictions:
log_wage_unemployed <- na.omit(data$d_unem * data$est_log_wage)

# Kernel density plot of log(Wage) predictions of the unemployed:
plot(density(log_wage_unemployed), xlab='log(Wage)', main='')
```

\clearpage

## Question 2: Earnings and Schooling

The same researcher is interested in estimating the causal effect of schooling on earnings for employed individuals only. As a consequence, she performs the subsequent analysis on the (sub)sample of employed individuals.

__(a) Discuss the estimation of the causal effect of schooling on earnings by OLS. In particular, address whether or not it is plausible that regularity conditions for applying OLS are satisfied.__

It is not plausible that the regularity conditions are satisfied. In particular, an observable such as an individual's __ability__ might be correlated with the wage, but also with the decision to live close to a school. Hence, the estimates suffer from endogeneity.

__(b) The researcher has collected data on two potential instrumental variables subsidy and distance for years of schooling.__

- __distance measures the distance between the school location and the residence of the individual while at school-going age.__
- __subsidy is an indicator depending on regional subsidies of families for covering school expenses.__
    
The researcher has the option to use only distance as an instrumental variable, or to use only the instrumental variable subsidy, or to use both distance and subsidy as instrumental variables. Perform instrumental variables estimation for these three options. Which option do you prefer? Include in your answer the necessary analyses and numbers on which you base your choice.

```{r}
firstoption <- ivreg(data = data, formula = 
                         logWage ~ age + age2 + schooling | distance + age + age2)

secondoption <- ivreg(data = data, formula =
                          logWage ~ age + age2 + schooling | subsidy + age + age2)

thirdoption <- ivreg(data = data, formula =
                          logWage ~ age + age2 + schooling | subsidy + distance + age 
                     + age2)
```

```{r results='asis'}
stargazer(firstoption, secondoption, thirdoption, font.size = "small", 
          style = "AER", 
          header = F)
```

We consider that the second option, to include only subsidy as an instrument, is the best option. The reason is that distance is unlikely to satisfy the exclusion restriction: distance is (to a certain extent) an endogenous variable: wealthier (or more able) parents may choose to live closer to school, and invest more in the education of their children (or genetically transmit ability). Since a potentially endogenous instrument must not be used as such, we prefer the estimates in equation 2. However, we see that the results show that distance has no predictive power in schooling, thus showing that the endogeneity is very small. Conditional on subsidy being a good instrument, then, the potential endogeneity does not substantially changes the estimates of schooling on earnings. 

(c) Compare the IV estimates with the OLS outcomes.  Under which conditions  would  you  prefer  OLS  over  IV?  Perform  a  test  and  use  the outcome of the test to support your choice between OLS and IV. Motivate your choice.

We first observe that the OLS estimate $\beta =$ `r coeffs_1[2]` is about half the magnitude of the IV-estimate. This means that the bias generated by OLS likely _downplays_ the actual effect (if the IV estimates satisfy the exclusion restriction). In case we would not trust the IV assumptions, we would prefer to trust the (conservative) estimate that downplays the effect, i.e. the OLS estimates. We can test whether the OLS estimates are substantially different from the IV estimates by conducting a Hausman test:

```{r hausman test}
hoi <- summary(
    secondoption, 
        diagnostics=TRUE)

hoi$diagnostics
```

The null hypothesis in the Hausman test is exogeneity of the _schooling_ variable. As becomes clear, the null hypothesis is marginally rejected, implying the _schooling_ is endogenous, but only marginally so. Hence, we would prefer to trust the IV estimates in this case. 

